Accurate detection and counting of potatoes during early-stage harvest are critical for yield estimation, automated sorting, and intelligent agricultural decision-making. However, natural field conditions—such as soil occlusion, overlapping tubers, and varying 3
illumination—pose significant challenges to reliable visual recognition. To address these issues, we present SCG-YOLOv8n, a lightweight and efficient detection framework based on the YOLOv8n architecture, specifically optimized for small-object recognition and real-time 6
deployment on mobile devices. Our model introduces three key modules: (1) SPD-Conv for enhancing spatial feature discrimination; (2) CARAFE for content-aware upsampling and context reconstruction; and (3) GSConv to balance detection accuracy with computational 9
efficiency. Extensive experiments on a field-collected potato dataset demonstrate that SCG-YOLOv8n outperforms YOLOv5n and vanilla YOLOv8n in precision, recall, and mean average precision (mAP). Post-training float16 quantization reduces the model size to 3.2 12
MB while maintaining fast inference speeds (30–85 ms/frame) on Android devices. We further develop and deploy a mobile application, PotatoDetector, which achieves a root mean square error (RMSE) of 1.38 and an R2 of 0.96 in real-world counting scenarios. The proposed framework provides a deployable and scalable solution for precision agriculture 16
and offers strong generalization potential for other tuber or root crop monitoring tasks.
